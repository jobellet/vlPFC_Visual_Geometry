{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jobellet/vlPFC_Visual_Geometry/blob/main/RSA_with_DNNs_processing_original_or_blurry_images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RSA with DNNs processing original or blurry images\n",
        "This script generates the figure comparing vlPFC representational geometry in the early and late time periods with DNN representations of the original images or the images that are blurred to simulate the information available from the magnocellular pathway\n",
        "\n",
        "## Private key\n",
        "For the notebook to download the data from the Figshare repository prior to acceptance of the manuscript you need to insert the private link token mentioned in the \"Code availability\" section of the manuscript."
      ],
      "metadata": {
        "id": "4kMzLJHklC27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" RSA with DNNs processing original or blurry images\n",
        "This script generates the figure comparing vlPFC representational geometry\n",
        "in the early and late time periods with DNN representations of the original\n",
        "images or the images that are blurred to simulate the information available\n",
        "from the magnocellular pathway\n",
        "\"\"\"\n",
        "private_link = input('Enter the private link token:')\n",
        "\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import rankdata\n",
        "from statsmodels.stats.multitest import multipletests\n",
        "from sklearn.manifold import MDS\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from matplotlib import colors as mcolors\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import time\n",
        "import re\n",
        "import pickle\n",
        "from joblib import Parallel, delayed\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import sys\n",
        "IN_COLAB = False\n",
        "IN_KAGGLE = False\n",
        "try:\n",
        "    if 'google.colab' in str(get_ipython()):\n",
        "        IN_COLAB = True\n",
        "except NameError:\n",
        "    pass\n",
        "if not IN_COLAB:\n",
        "    if os.environ.get('KAGGLE_KERNEL_RUN_TYPE', 'Localhost') == 'Interactive':\n",
        "        IN_KAGGLE = True\n",
        "\n",
        "\n",
        "# Determine the path to the repository based on the environment\n",
        "if IN_COLAB:\n",
        "    path_to_repo = '/content/vlPFC_Visual_Geometry'\n",
        "elif IN_KAGGLE:\n",
        "    path_to_repo = '/kaggle/working/vlPFC_Visual_Geometry'\n",
        "else:\n",
        "    # Assume local environment where the .py file is in the root of the repo\n",
        "    path_to_repo = '.'\n",
        "\n",
        "\n",
        "# Only clone if not already present\n",
        "if not os.path.exists(path_to_repo):\n",
        "    os.system(\"git clone https://github.com/jobellet/vlPFC_Visual_Geometry.git \" + path_to_repo)\n",
        "\n",
        "sys.path.append(path_to_repo)\n",
        "sys.path.append(os.path.join(path_to_repo, 'utils')) # Add the utils directory to sys.path\n",
        "\n",
        "\n",
        "from utils.extract_and_download_data import download_files, unzip\n",
        "\n",
        "from utils.analysis_utils import (get_upper_indices, pairwise_euclidean_distance,\n",
        "                                  spearman_corr_ranked, training_kind, round_robin_pairs,\n",
        "                                  pairs_to_batches, perm_signflip_onesample, perm_diff_independent, condensed)\n",
        "from utils.plotting_utils import q_to_stars\n",
        "\n",
        "jax.config.update(\"jax_enable_x64\", True)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "rng_global = np.random.default_rng(42)\n",
        "\n",
        "BATCH_SIZE  = 16\n",
        "TIME_WINDOWS = {                       # indices on the >0 ms axis\n",
        "    \"50–90 ms\":   slice(5,  9),        # 50–90 ms\n",
        "    \"100–200 ms\": slice(10, 20)        # 105–195 ms\n",
        "}\n",
        "PALETTE = {                            # Okabe–Ito, red-green safe\n",
        "    \"50–90 ms\":   \"#56B4E9\",\n",
        "    \"100–200 ms\": \"#009E73\"\n",
        "}\n",
        "MARKERS = {\"Supervised\": \"s\", \"Self-supervised\": \"^\", \"Language Aligned\": \"x\"}\n",
        "N_PERM  = 10_000\n",
        "\n",
        "FIGURES_DIR = Path(\"Figures\")\n",
        "STATISTICS_DIR = Path(\"Statistics\")\n",
        "\n",
        "plt.rcParams.update({\n",
        "    \"figure.dpi\":         300,\n",
        "    \"axes.spines.top\":    False,\n",
        "    \"axes.spines.right\":  False,\n",
        "    \"axes.labelsize\":     11,\n",
        "    \"xtick.labelsize\":    10,\n",
        "    \"ytick.labelsize\":    10,\n",
        "})\n",
        "FIGURES_DIR.mkdir(exist_ok=True)\n",
        "STATISTICS_DIR.mkdir(exist_ok=True) # Create the Statistics directory\n",
        "\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "#  3.  Data download (first run only)\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "download_files(path_to_repo, [\"deepNetFeatures.zip\", \"Spike_count_even_sessions.npy\", \"Spike_count_odd_sessions.npy\", \"hvm_public_extended_meta.csv\"], private_link=private_link)\n",
        "unzip(Path(\"downloads\") / \"deepNetFeatures.zip\", \"deepNetFeatures\")\n",
        "\n",
        "meta           = pd.read_csv(Path(\"downloads\") / \"hvm_public_extended_meta.csv\")\n",
        "spike_counts_even, spike_counts_odd      = np.load(Path(\"downloads\") / \"Spike_count_even_sessions.npy\"), np.load(Path(\"downloads\") / \"Spike_count_odd_sessions.npy\")\n",
        "\n",
        "spike_counts  = .5 * (spike_counts_even+spike_counts_odd)\n",
        "n_stim = spike_counts.shape[0]\n",
        "stim_base = meta['image_id'].str.strip().tolist()\n",
        "\n",
        "def slice_flat(arr, slc):\n",
        "    return arr[:, :, slc].reshape(n_stim, -1)\n",
        "\n",
        "neural = {lbl: slice_flat(spike_counts, sli) for lbl, sli in TIME_WINDOWS.items()}\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "#  5.  Load DNN features\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "feat_dir, patt = Path(\"deepNetFeatures\"), re.compile(r\"^(?P<net>.*)_features_high_variation_(?P<flav>original|lowpass)\\.pkl$\")\n",
        "feat = defaultdict(dict)\n",
        "for pkl in feat_dir.glob(\"*.pkl\"):\n",
        "    if (m := patt.match(pkl.name)):\n",
        "        with open(pkl, \"rb\") as fh:\n",
        "            feat[m[\"net\"]][m[\"flav\"]] = pickle.load(fh)\n",
        "\n",
        "feat  = {k: v for k, v in feat.items() if set(v) == {\"original\", \"lowpass\"}}\n",
        "nets  = sorted(feat)\n",
        "train_type = {n: training_kind(n) for n in nets}\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "#  6.  RSA computation (pair-unique 16-stim batches)\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "rsa = {lbl: {} for lbl in TIME_WINDOWS}\n",
        "for net in nets:\n",
        "    f_o, f_l = feat[net][\"original\"][\"penultimate\"], feat[net][\"lowpass\"][\"penultimate\"]\n",
        "    if f_o.ndim > 2: f_o = f_o.reshape(f_o.shape[0], -1)\n",
        "    if f_l.ndim > 2: f_l = f_l.reshape(f_l.shape[0], -1)\n",
        "\n",
        "    names_o = [Path(x).stem for x in feat[net][\"original\"][\"image_names\"]]\n",
        "    names_l = [Path(x).stem for x in feat[net][\"lowpass\"][\"image_names\"]]\n",
        "    common  = sorted(set(names_o) & set(names_l) & set(stim_base))\n",
        "    if len(common) < BATCH_SIZE:\n",
        "        warnings.warn(f\"{net}: skipped (only {len(common)} common stimuli)\"); continue\n",
        "\n",
        "    idx_o = np.array([names_o.index(s)   for s in common])\n",
        "    idx_l = np.array([names_l.index(s)   for s in common])\n",
        "    idx_n = np.array([stim_base.index(s) for s in common])\n",
        "\n",
        "    rr, batches = round_robin_pairs(len(common), rng_global), []\n",
        "    for rnd in rr: batches.extend(pairs_to_batches(rnd, BATCH_SIZE))\n",
        "    batches = batches[:len(common) // BATCH_SIZE]\n",
        "\n",
        "    accum = {lbl: {\"o\": [], \"l\": []} for lbl in TIME_WINDOWS}\n",
        "    for b in batches:\n",
        "        # The 'condensed' function is now in utils/analysis_utils.py\n",
        "        # and imported at the top of this file.\n",
        "        r_o, r_l = rankdata(condensed(f_o[idx_o[b]])), rankdata(condensed(f_l[idx_l[b]]))\n",
        "        for lbl, neu_mat in neural.items():\n",
        "            r_n = rankdata(condensed(neu_mat[idx_n[b]]))\n",
        "            accum[lbl][\"o\"].append(spearman_corr_ranked(r_n, r_o))\n",
        "            accum[lbl][\"l\"].append(spearman_corr_ranked(r_n, r_l))\n",
        "\n",
        "    for lbl in TIME_WINDOWS:\n",
        "        for k in (\"o\", \"l\"):\n",
        "            vec, mu, sem = np.asarray(accum[lbl][k]), None, None\n",
        "            mu = float(vec.mean()); sem = float(vec.std(ddof=1) / np.sqrt(len(vec)))\n",
        "            accum[lbl][k] = (mu, sem)\n",
        "        rsa[lbl][net] = (*accum[lbl][\"o\"], *accum[lbl][\"l\"])\n",
        "\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "#  7.  Gather vectors per window & stats\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "vals, one_p, pair_p = {}, {}, {}\n",
        "for lbl in TIME_WINDOWS:\n",
        "    mu_o = np.array([rsa[lbl][n][0] for n in nets if n in rsa[lbl]])\n",
        "    se_o = np.array([rsa[lbl][n][1] for n in nets if n in rsa[lbl]])\n",
        "    mu_l = np.array([rsa[lbl][n][2] for n in nets if n in rsa[lbl]])\n",
        "    se_l = np.array([rsa[lbl][n][3] for n in nets if n in rsa[lbl]])\n",
        "    kept = [n for n in nets if n in rsa[lbl]]\n",
        "    vals[lbl] = (mu_o, se_o, mu_l, se_l, kept)\n",
        "\n",
        "    # one-sample (Orig, LP) and paired (Orig vs LP) – same as before\n",
        "    _, _, p_o = perm_signflip_onesample(mu_o, N_PERM, greater=True)\n",
        "    _, _, p_l = perm_signflip_onesample(mu_l, N_PERM, greater=True)\n",
        "    one_p[lbl] = (p_o, p_l)\n",
        "\n",
        "    _, _, p_pair = perm_diff_independent(mu_o, mu_l, N_PERM, two_sided=True)\n",
        "    pair_p[lbl] = p_pair\n",
        "\n",
        "# FDR across all the above p’s\n",
        "raw_p = [*sum(one_p.values(), ()), *pair_p.values()]\n",
        "_, q_all, *_ = multipletests(raw_p, method=\"fdr_bh\")\n",
        "q_iter, q_one, q_pair = iter(q_all), {}, {}\n",
        "for lbl in TIME_WINDOWS:        # Orig, LP\n",
        "    q_one[lbl] = (next(q_iter), next(q_iter))\n",
        "for lbl in TIME_WINDOWS:        # paired\n",
        "    q_pair[lbl] = next(q_iter)\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "#  8.  Scatter plot\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "def group_stats(values, types):\n",
        "    df = pd.DataFrame({'val': values, 'kind': types})\n",
        "    return df.groupby('kind')['val'].mean(), df.groupby('kind')['val'].sem(ddof=1)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5, 5)); ax.set_aspect('equal')\n",
        "\n",
        "for lbl, (xo, _, xl, _, kept) in vals.items():\n",
        "    col, kinds = PALETTE[lbl], [training_kind(n) for n in kept]\n",
        "\n",
        "    # 1 individual nets\n",
        "    for xi, yi, k in zip(xo, xl, kinds):\n",
        "        ax.scatter(xi, yi, s=24, marker=MARKERS[k], c=col, alpha=.6, edgecolors='none')\n",
        "\n",
        "    # 2 group means ± SEM\n",
        "    μx, σx = group_stats(xo, kinds); μy, σy = group_stats(xl, kinds)\n",
        "    for k in μx.index:\n",
        "        ax.errorbar(μx[k], μy[k], xerr=σx[k], yerr=σy[k],\n",
        "                    fmt=MARKERS[k], mfc='white', mec=col,\n",
        "                    ecolor=col, elinewidth=.95, capsize=3, zorder=4, ms=8)\n",
        "\n",
        "lims = np.array([ax.get_xlim(), ax.get_ylim()]).flatten(); lims = lims.min(), lims.max()\n",
        "ax.plot(lims, lims, lw=.8, c='0.35'); ax.set_xlim(lims); ax.set_ylim(lims)\n",
        "ax.axhline(0, lw=.6, c='0.4', ls=':'); ax.axvline(0, lw=.6, c='0.4', ls=':')\n",
        "ax.set_xlabel(\"RSA original (Spearman r)\"); ax.set_ylabel(\"RSA low-pass \\n (Spearman r)\", rotation = 0, labelpad=40)\n",
        "\n",
        "handles = ([plt.Line2D([0], [0], marker='o', ls='', c=PALETTE[lbl]) for lbl in TIME_WINDOWS] +\n",
        "           [plt.Line2D([0], [0], marker=MARKERS[k], ls='', c='k')     for k in MARKERS])\n",
        "labels  = list(TIME_WINDOWS.keys()) + list(MARKERS.keys())\n",
        "ax.legend(handles, labels, fontsize=9, frameon=False,\n",
        "          title=\"\", title_fontsize=9,\n",
        "          loc='upper left', bbox_to_anchor=(1.02, 1))\n",
        "\n",
        "ax.set_xticks([0,.25]); ax.set_yticks([0,.25])\n",
        "sns.despine(ax=ax,trim=True)\n",
        "fig.tight_layout()\n",
        "fig.savefig(FIGURES_DIR / \"RSA_three_windows_minimal.pdf\", bbox_inches=\"tight\")\n",
        "fig.savefig(FIGURES_DIR / \"RSA_three_windows_minimal.jpeg\", dpi=300, bbox_inches=\"tight\")\n",
        "if IN_COLAB or IN_KAGGLE:\n",
        "    plt.show()\n",
        "else:\n",
        "    plt.close(fig)\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "#  9.  Statistics tables\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "from IPython.display import display\n",
        "\n",
        "def direction_tt(mu_a, mu_b, grp_a, grp_b):\n",
        "    if np.isclose(mu_a, mu_b): return \"≈\"\n",
        "    return f\"{grp_a} > {grp_b}\" if mu_a > mu_b else f\"{grp_b} > {grp_a}\"\n",
        "\n",
        "# 9 a) one-sample & image-condition paired tests\n",
        "rows = []\n",
        "for lbl in TIME_WINDOWS:\n",
        "    mu_o, _, mu_l, _, _ = vals[lbl]\n",
        "    diff                = mu_o.mean() - mu_l.mean()\n",
        "\n",
        "    p_o, p_l            = one_p[lbl]\n",
        "    q_o, q_l            = q_one[lbl]\n",
        "    p_pair, q_pair_w    = pair_p[lbl], q_pair[lbl]\n",
        "\n",
        "    rows += [\n",
        "        dict(Window=lbl, Condition=\"Original\",  Mean=mu_o.mean(),\n",
        "             SEM=mu_o.std(ddof=1)/np.sqrt(len(mu_o)),\n",
        "             Direction=\"\", p=p_o, q=q_o, Sig=q_to_stars(q_o)),\n",
        "        dict(Window=lbl, Condition=\"Low-pass\",  Mean=mu_l.mean(),\n",
        "             SEM=mu_l.std(ddof=1)/np.sqrt(len(mu_l)),\n",
        "             Direction=\"\", p=p_l, q=q_l, Sig=q_to_stars(q_l)),\n",
        "        dict(Window=lbl, Condition=\"Orig – LP\", Mean=diff, SEM=np.nan,\n",
        "             Direction=(\"Orig > LP\" if diff > 0 else \"LP > Orig\"),\n",
        "             p=p_pair, q=q_pair_w, Sig=q_to_stars(q_pair_w)) # Fixed stars function call\n",
        "    ]\n",
        "\n",
        "stats_df = (pd.DataFrame(rows)\n",
        "              .loc[:, [\"Window\",\"Condition\",\"Mean\",\"SEM\",\n",
        "                       \"Direction\",\"p\",\"q\",\"Sig\"]]\n",
        "              .round({\"Mean\":3, \"SEM\":3, \"p\":4, \"q\":4}))\n",
        "stats_df.to_csv(STATISTICS_DIR / \"RSA_summary_stats.csv\", index=False)\n",
        "\n",
        "# 9 b) training-type comparisons on (RSA_orig + RSA_lp)/2\n",
        "pair_rows = []\n",
        "for lbl in TIME_WINDOWS:\n",
        "    kept   = vals[lbl][4]\n",
        "    kinds  = pd.Series({n: training_kind(n) for n in kept})\n",
        "    mu_o   = pd.Series(vals[lbl][0], index=kept)\n",
        "    mu_l   = pd.Series(vals[lbl][2], index=kept)\n",
        "    mu_avg = .5 * (mu_o + mu_l)                 # ← overall RSA\n",
        "\n",
        "    for a in kinds.unique():\n",
        "        for b in kinds.unique():\n",
        "            if a >= b:                          # unordered pairs once\n",
        "                continue\n",
        "            xa, xb = mu_avg[kinds==a], mu_avg[kinds==b]\n",
        "            _, _, p = perm_diff_independent(xa, xb, N_PERM)\n",
        "            pair_rows.append(dict(Window    = lbl,\n",
        "                                   GroupA    = a,\n",
        "                                   GroupB    = b,\n",
        "                                   Direction = direction_tt(xa.mean(), xb.mean(), a, b),\n",
        "                                   p         = p))\n",
        "\n",
        "# FDR across *all* these p’s\n",
        "pairwise_df = pd.DataFrame(pair_rows)\n",
        "_, q_vals, *_       = multipletests(pairwise_df[\"p\"], method=\"fdr_bh\")\n",
        "pairwise_df[\"q\"]    = q_vals\n",
        "pairwise_df[\"Sig\"]  = [q_to_stars(q) for q in q_vals] # Fixed stars function call\n",
        "\n",
        "pairwise_df = (pairwise_df\n",
        "                 .round({\"p\":4, \"q\":4})\n",
        "                 .loc[:, [\"Window\",\"GroupA\",\"GroupB\",\"Direction\",\"p\",\"q\",\"Sig\"]])\n",
        "pairwise_df.to_csv(STATISTICS_DIR / \"RSA_pairwise_trainingtype.csv\", index=False)\n",
        "\n",
        "# ── show in interactive sessions\n",
        "display(stats_df)\n",
        "display(pairwise_df)\n",
        "\n",
        "\"\"\"# Display MDS of original and low passed representational geometries of a DNN of a batch of images\"\"\"\n",
        "\n",
        "#!/usr/bin/env python\n",
        "\"\"\"\n",
        "Script 2 — CLIP‑average RDM → MDS visualisation\n",
        "------------------------------------------------\n",
        "For a *single* 16‑image batch we:\n",
        "1. Load all CLIP‑based networks’ penultimate‑layer feature tensors (pre‑computed\n",
        "   in `deepNetFeatures/*_features_high_variation_{original|lowpass}.pkl`).\n",
        "2. Compute the pairwise‑Euclidean representational‑dissimilarity matrix (RDM)\n",
        "   for *each* network and flavour (original vs. low‑pass).\n",
        "3. Average those RDMs across networks → one mean RDM per flavour.\n",
        "4. Run metric‑MDS (2‑D) on each averaged RDM.\n",
        "5. Render the two layouts with `plot_many_images_in_one_canevas`, saving to\n",
        "   *Figures/MDS_CLIP_batch_original.png* and *Figures/MDS_CLIP_batch_lowpass.png*.\n",
        "\n",
        "The batch is chosen reproducibly with `numpy.random.default_rng(42)`.\n",
        "\"\"\"\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "# 0. Imports & housekeeping\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "from utils.extract_and_download_data import download_figshare_file, unzip, download_files\n",
        "from utils.image_processing import m_pathway_filter_gaussian\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "plt.rcParams.update({\n",
        "    \"figure.dpi\":         300,\n",
        "    \"axes.spines.top\":    False,\n",
        "    \"axes.spines.right\":  False,\n",
        "})\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "# 1. Constants & directories\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "\n",
        "FIGURES_DIR = Path(\"Figures\")\n",
        "STATISTICS_DIR = Path(\"Statistics\")\n",
        "\n",
        "FIG_DIR      = FIGURES_DIR\n",
        "STIM_DIR     = Path(\"high_variation_stimuli\")\n",
        "LP_DIR       = Path(\"high_variation_stimuli_lowpass\")\n",
        "FEAT_DIR     = Path(\"deepNetFeatures\")\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "# 2. Ensure stimulus sets are present\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "\n",
        "print(\"▶ Checking / downloading stimulus images …\")\n",
        "download_files(path_to_repo, [\"high_variation_stimuli.zip\"], private_link=private_link)\n",
        "unzip(Path(\"downloads\") / \"high_variation_stimuli.zip\", \"\")\n",
        "\n",
        "# build low‑pass set only if directory is still empty\n",
        "LP_DIR.mkdir(exist_ok=True)\n",
        "if not any(LP_DIR.iterdir()):\n",
        "    print(\"▶ Creating low‑pass stimulus set (magnocellular filter) …\")\n",
        "    img_files = sorted(STIM_DIR.glob(\"*.png\"))\n",
        "    for img_path in tqdm(img_files):\n",
        "        img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)\n",
        "        if img is None:\n",
        "            continue\n",
        "        lp  = m_pathway_filter_gaussian(img)\n",
        "        # OpenCV expects 8‑ or 32‑bit depths for colour conversion → cast\n",
        "        if lp.dtype != np.uint8:\n",
        "            lp = np.clip(lp, 0, 255).astype(np.uint8)\n",
        "        lp_rgb = cv2.cvtColor(lp, cv2.COLOR_GRAY2RGB)\n",
        "        cv2.imwrite(str(LP_DIR / img_path.name), lp_rgb)\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "# 3. Ensure CLIP feature pickles are present\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "\n",
        "print(\"▶ Checking / downloading DNN feature pickles …\")\n",
        "unzip(Path(\"downloads\") / \"deepNetFeatures.zip\", \"deepNetFeatures\")\n",
        "\n",
        "# gather *all* nets that have both flavours; keep only CLIP/Language‑aligned\n",
        "feat_paths = {}\n",
        "patt = re.compile(r\"^(?P<net>.*)_features_high_variation_(?P<flav>original|lowpass)\\.pkl$\", re.I)\n",
        "for pkl in FEAT_DIR.glob(\"*.pkl\"):\n",
        "    if m := patt.match(pkl.name):\n",
        "        net, flav = m[\"net\"], m[\"flav\"]\n",
        "        feat_paths.setdefault(net, {})[flav] = pkl\n",
        "\n",
        "\n",
        "\n",
        "clip_nets = sorted([n for n, d in feat_paths.items()\n",
        "                    if set(d) == {\"original\", \"lowpass\"} and training_kind(n) == \"Language Aligned\"])  # noqa\n",
        "if not clip_nets:\n",
        "    raise RuntimeError(\"No CLIP (Language‑aligned) networks with both flavours found in deepNetFeatures.\\n\"\n",
        "                       \"Please verify that the ZIP extracted correctly and contains the expected pickles.\")\n",
        "print(f\"  → Using {len(clip_nets)} CLIP nets: {', '.join(clip_nets)}\")\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "# 4. Determine common stimulus pool & choose batch\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "\n",
        "def _load_names(pkl_path):\n",
        "    with open(pkl_path, \"rb\") as fh:\n",
        "        return [Path(p).stem for p in pickle.load(fh)[\"image_names\"]]\n",
        "\n",
        "names_all = [set(_load_names(feat_paths[n][\"original\"])) &\n",
        "             set(_load_names(feat_paths[n][\"lowpass\"])) for n in clip_nets]\n",
        "common = sorted(set.intersection(*names_all))\n",
        "if len(common) < BATCH_SIZE:\n",
        "    raise RuntimeError(\"Shared stimulus count is smaller than batch size.\")\n",
        "\n",
        "batch_idx   = rng_global.choice(len(common), size=BATCH_SIZE, replace=False)\n",
        "batch_names = [common[i] for i in batch_idx]\n",
        "print(\"▶ Batch:\", \", \".join(batch_names))\n",
        "\n",
        "_flatten = lambda a: a.reshape(a.shape[0], -1) if a.ndim > 2 else a\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "# 5. Build mean RDMs (original & low‑pass)\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "from scipy.stats import rankdata\n",
        "rdm_o_all, rdm_l_all = [], []\n",
        "for net in clip_nets:\n",
        "    with open(feat_paths[net][\"original\"], \"rb\") as fh:\n",
        "        f_o = _flatten(pickle.load(fh)[\"penultimate\"])\n",
        "    with open(feat_paths[net][\"lowpass\"], \"rb\") as fh:\n",
        "        f_l = _flatten(pickle.load(fh)[\"penultimate\"])\n",
        "\n",
        "    names_net = _load_names(feat_paths[net][\"original\"])\n",
        "    idx       = np.array([names_net.index(b) for b in batch_names])\n",
        "\n",
        "    rdm_o_all.append(rankdata(pdist(f_o[idx], metric=\"euclidean\")))\n",
        "    rdm_l_all.append(rankdata(pdist(f_l[idx], metric=\"euclidean\")))\n",
        "\n",
        "mean_rdm_o = np.mean(rdm_o_all, axis=0)\n",
        "mean_rdm_l = np.mean(rdm_l_all, axis=0)\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "# 6. Metric‑MDS (2‑D)\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "\n",
        "print(\"▶ Running metric‑MDS …\")\n",
        "mds = MDS(n_components=2, dissimilarity=\"precomputed\", random_state=42)\n",
        "coords_o = mds.fit_transform(squareform(mean_rdm_o))\n",
        "coords_l = mds.fit_transform(squareform(mean_rdm_l))\n",
        "\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "# 7. Plot helper (with circular alpha mask)\n",
        "# ──────────────────────────────────────────────────────────────────────\n",
        "\n",
        "\n",
        "def plot_many_images_in_one_canevas(coordinates, impaths):\n",
        "    \"\"\"Draw 128×128 thumbnails with a 4-px colour-blind-safe ring (r = 60–64 px).\"\"\"\n",
        "    # ── deterministic colour-blind-safe palette (16 colours) ──────────────\n",
        "    palette_hex = [\n",
        "        \"#000000\", \"#252525\", \"#676767\", \"#009E73\",\n",
        "        \"#505050\", \"#004949\", \"#009999\", \"#22CF22\",\n",
        "        \"#490092\", \"#006DDB\", \"#B66DFF\", \"#FF6DB6\",\n",
        "        \"#920000\", \"#8F4E00\", \"#DB6D00\", \"#FFDF4D\",\n",
        "    ]\n",
        "    colors = np.array([mcolors.to_rgb(h) for h in palette_hex], float)\n",
        "\n",
        "    # ── coordinate normalisation (as in your original) ────────────────────\n",
        "    image_res   = 850\n",
        "    coords_norm = (image_res - 128) * (coordinates - coordinates.min(0)) \\\n",
        "                  / (coordinates.max(0) - coordinates.min(0))\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 10)); ax.axis(\"off\")\n",
        "    canvas  = np.ones((image_res, image_res, 3), float)\n",
        "\n",
        "    # circular masks\n",
        "    yy, xx   = np.ogrid[:128, :128]\n",
        "    dist2    = (xx - 64) ** 2 + (yy - 64) ** 2\n",
        "    mask_img = dist2 < 60 ** 2                     # interior of disk\n",
        "    mask_ring = (60 ** 2 <= dist2) & (dist2 < 64 ** 2)   # 4-px annulus\n",
        "\n",
        "    for i, path in enumerate(impaths):\n",
        "        x, y = map(int, coords_norm[i])\n",
        "        arr  = np.asarray(Image.open(path).resize((128, 128)))\n",
        "\n",
        "        if arr.ndim == 2:                          # greyscale → RGB\n",
        "            arr = np.stack([arr]*3, axis=2)\n",
        "        arr = arr[..., :3] / 255.0                 # normalise\n",
        "\n",
        "        patch = canvas[y:y+128, x:x+128]\n",
        "        patch[mask_ring] = colors[i % len(colors)] # colour ring\n",
        "        patch[mask_img]  = arr[mask_img]           # image\n",
        "        canvas[y:y+128, x:x+128] = patch\n",
        "\n",
        "    ax.imshow(canvas)\n",
        "    plt.tight_layout()\n",
        "    return fig\n",
        "\n",
        "\n",
        "# gather paths for batch\n",
        "orig_paths = [STIM_DIR / f\"{b}.png\" for b in batch_names]\n",
        "lowp_paths = [LP_DIR   / f\"{b}.png\" for b in batch_names]\n",
        "\n",
        "print(\"▶ Rendering & saving figures …\")\n",
        "fig_o = plot_many_images_in_one_canevas(coords_o, orig_paths)\n",
        "fig_l = plot_many_images_in_one_canevas(coords_l, lowp_paths)\n",
        "\n",
        "fig_o.savefig(FIGURES_DIR / \"MDS_CLIP_batch_original.pdf\", bbox_inches=\"tight\")\n",
        "fig_o.savefig(FIGURES_DIR / \"MDS_CLIP_batch_original.jpeg\", dpi=300, bbox_inches=\"tight\")\n",
        "if IN_COLAB or IN_KAGGLE:\n",
        "    plt.show()\n",
        "else:\n",
        "    plt.close(fig_o)\n",
        "fig_l.savefig(FIGURES_DIR / \"MDS_CLIP_batch_lowpass.pdf\", bbox_inches=\"tight\")\n",
        "fig_l.savefig(FIGURES_DIR / \"MDS_CLIP_batch_lowpass.jpeg\", dpi=300, bbox_inches=\"tight\")\n",
        "if IN_COLAB or IN_KAGGLE:\n",
        "    plt.show()\n",
        "else:\n",
        "    plt.close(fig_l)\n",
        "\n",
        "print(\"✓ Done – figures saved in the ‘Figures’ directory.\")"
      ],
      "metadata": {
        "id": "gipW87cgo7bS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BZEB-KUgoMCs"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}